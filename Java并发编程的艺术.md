### Java并发编程的艺术

#### 第一章 并发编程的挑战

对于Java开发工程师而言，笔者强烈建议多使用JDK并发包提供的并发容器和工具类来解决并发问题。

并发编程可能会遇到的3个问题：



##### 1.1 上下文切换

**上下文：**

任务从保存到再加载的过程就是一次上下文切换。

并发不一定比串行要快，因为线程有创建和上下文切换的开销。

**减少上下文切换的方法：**

+ **无锁并发编程。**多线程竞争锁时，会引起上下文切换，所以多线程处理数据时，可以用一些办法来避免使用锁，如将数据的ID按照Hash算法取模分段，**不同的线程处理不同段的数据**。
+ **CAS算法。**Java的Atomic包使用CAS算法来更新数据，而不需要加锁。
+ **使用最少线程。**避免创建不需要的线程，比如任务很少，但是创建了很多线程来处理，这样会造成大量线程都处于等待状态。
+ **协程：**在单线程里实现多任务的调度，并在单线程里维持多个任务间的切换。



##### **1.2 死锁**

**避免死锁的几个常见方法：**

+ 避免一个线程同时获取多个锁。（避免1线程n锁
+ 避免一个线程在锁内同时占用多个资源，尽量保证每个锁只占用一个资源。（避免1锁n资源
+ 尝试使用定时锁，使用lock.tryLock（timeout）来替代使用内部锁机制。（定时
+ 对于数据库锁，加锁和解锁必须在一个数据库连接里，否则会出现解锁失败的情况。（同一个数据库连接中加锁解锁



##### 1.3 资源限制的挑战

+ **资源限制：**硬件资源限制有带宽的上传/下载速度、硬盘读写速度和CPU的处理速度。软件资源限制有数据库的连接数和socket连接数等。
+ **资源限制引发的问题**：资源限制的情况下进行并发编程，只会降低效率。
+ **如何解决资源限制的问题**：对于硬件资源限制，可以考虑使用集群并行执行程序。对于软件资源限制，可以考虑使用资源池将资源复用。比如使用连接池将数据库和Socket连接复用，或者在调用对方webservice接口获取数据时，只建立一个连接。
+ **在资源限制情况下进行并发编程**：根据不同的资源限制调整程序的并发度。





#### 第二章 Java并发机制的底层实现原理

Java中所使用的并发机制**依赖于JVM的实现和CPU的指令。**



##### 2.1 volatile的应用

保证了可见性，禁止指令重排序，不保证原子性（变量的读写有原子性，volatile++这种就不具备原子性）。

**volatile的定义**

Java编程语言允许线程访问共享变量，为了确保共享变量能被准确和一致地更新，线程应该确保通过排他锁单独获得这个变量。

**实现原理**

有volatile变量修饰的共享变量进行写操作的时候会多出第二行汇编代码—— Lock前缀的指令在多核处理器下会做两件事。

+ 1）将当前处理器缓存行的数据写回到系统内存。
+ 2）这个写回内存的操作会使在其他CPU里缓存了该内存地址的数据无效。



##### 2.2 Synchronized应用

synchronized实现同步的基础：Java中的每一个对象都可以作为锁。

+ 对于普通同步方法，锁是当前实例对象。
+ 对于静态同步方法，锁是当前类的Class对象。
+ 对于同步方法块，锁是Synchonized括号里配置的对象。



**Synchonized在JVM里的实现原理：**

+  JVM基于进入和退出Monitor对象来实现方法同步和代码块同步，但两者的实现细节不一样。
+ 任何对象都有一个monitor与之关联，当且一个monitor被持有后，它将处于锁定状态。线程执行到monitorenter指令时，将会尝试获取对象所对应的monitor的所有权，即尝试获得对象的锁。



**Java对象头**

 一般对象头是2个字宽（一个字宽是32/64bit），第一个字宽：mark word（hashcode、分代年龄、锁等），第二个字宽：对象类型数据的指针；

数组对象是3个字宽，第三个字宽存放数组的长度



**锁的升级和对比**

在Java SE 1.6中，锁一共有4种状态，级别从低到高依次是：这几个状态会随着竞争情况逐渐升级。锁可以升级但不能降级，

+ 无锁

+ 偏向锁：**大多数情况总是同一个线程获得锁的情况，偏向锁更有优势**。当一个线程访问同步块并获取锁时，会在对象头和栈帧中的锁记录里存储锁偏向的线程ID，以后该线程在进入和退出同步块时不需要进行CAS操作来加锁和解锁。一种等到竞争出现才释放锁。

+ 轻量级锁：线程在执行同步块之前，JVM会先在当前线程的**栈桢中创建用于存储锁记录的空间**，并将对象头中的Mark Word复制到锁记录中，官方称为Displaced MarkWord。然后线程尝试使用CAS将对象头中的Mark Word替换为指向锁记录的指针。如果成功，当前线程获得锁，如果失败，表示其他线程竞争锁，当前线程便尝试使用自旋来获取锁。

  轻量级解锁时，会使用原子的CAS操作将Displaced Mark Word替换回到对象头。如果成功，则表示没有竞争发生。如果失败，表示当前锁存在竞争，锁就会膨胀成重量级锁。

+ 重量级锁

![image-20200619154750418](/Users/chengleiyi/Library/Application Support/typora-user-images/image-20200619154750418.png)

##### 2.3 原子操作的实现原理

原子操作（atomicoperation）**意为“不可被中断的一个或一系列操作”。**

![image-20200619154950565](/Users/chengleiyi/Library/Application Support/typora-user-images/image-20200619154950565.png) 

**处理器如何实现原子操作**

处理器使用基于对**缓存加锁**或**总线加锁**的方式来实现多处理器之间的原子操作。

处理器一般默认保证单处理器对同一个缓存行进行xxbit的操作是原子的，但是复杂的内存操作就不能自动保证（比如跨多个缓存行的访问）。

+ 总线锁定：所谓总线锁就是使用处理器提供的一个LOCK #信号，当一个处理器在总线上输出此信号时，其他处理器的请求将被阻塞住，那么该处理器可以独占共享内存。

+ 缓存锁定：总线锁定的开销比较大，因为总线锁定了，其他内存区域也不能操作。所谓“缓存锁定”是指内存区域如果被缓存在处理器的缓存行中，并且在Lock操作期间被锁定，那么当它执行锁操作回写到内存时，处理器不在总线上声言LOCK #信号，而是修改内部的内存地址，并允许它的缓存一致性机制来保证操作的原子性

  但有两种情况不能用

  第一种情况是：当操作的数据不能被缓存在处理器内部，或操作的数据跨多个缓存行（cache line）时，则处理器会调用总线锁定。第二种情况是：有些处理器不支持缓存锁定。对于Intel 486和Pentium处理器，就算锁定的内存区域在处理器的缓存行中也会调用总线锁定。



**Java如何实现原子性**

+ 循环CAS：
  + ABA问题：因为CAS需要在操作值的时候，检查值有没有发生变化，如果没有发生变化则更新，但是如果一个值原来是A，变成了B，又变成了A，那么使用CAS进行检查时会发现它的值没有发生变化，但是实际上却变化了---- **解决办法：使用版本号**
  + 循环时间长开销大：自旋CAS如果长时间不成功，会给CPU带来非常大的执行开销。如果JVM能支持处理器提供的pause指令，那么效率会有一定的提升。
  + 只能保证一个共享变量的原子操作：**解决办法：使用锁或者把多个变量合并为一个来CAS**
+ 锁机制：JVM除了偏向锁，其他锁也都是依赖循环CAS来获取/释放锁



#### 第三章 Java内存模型

##### 3.1 Java内存模型的基础

并发编程的关键性问题：如何解决线程之间的通信？

命令式编程中，有两种机制：**共享内存和消息传递。**

+ 共享内存：共享程序的公共状态，隐式通信，显示的同步控制
+ 消息传递：没有公共状态，必须显式的发送消息来通信，隐式的同步控制（消息的发送必须在消息的接受之前）
+ **Java的并发采用的是共享内存模型**



**Java的内存模型抽象结构**

从抽象的角度来看，JMM定义了线程和主内存之间的抽象关系：线程之间的共享变量存储在主内存（Main Memory）中，每个线程都有一个私有的本地内存（Local Memory），本地内存中存储了该线程以读/写共享变量的副本。本地内存是JMM的一个抽象概念，并不真实存在。它涵盖了缓存、写缓冲区、寄存器以及其他的硬件和编译器优化。

JMM通过控制主内存与每个线程的本地内存之间的交互，来为Java程序员提供内存可见性保证。



**重排序**

为了提高性能，编译器和处理器常常会对指令做重排序：

+ **编译器优化的重排序**。编译器在不改变**单线程**程序语义的前提下，可以重新安排语句的执行顺序。
+ **指令级并行的重排序**。现代处理器采用了**指令级并行技术**（Instruction-LevelParallelism，ILP）来将多条指令重叠执行。如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序。
+ **内存系统的重排序**。由于处理器使用缓存和读/写缓冲区，这使得**加载和存储操作**看上去可能是在乱序执行。

上述的1属于编译器重排序，2和3属于处理器重排序。

这些重排序可能会导致多线程程序出现内存可见性问题。对于编译器，<u>JMM的编译器重排序规则会禁止特定类型的编译器重排序（不是所有的编译器重排序都要禁止）</u>。对于处理器重排序，JMM的处理器重排序规则会要求Java编译器在生成指令序列时，<u>插入特定类型的内存屏障</u>（Memory Barriers，Intel称之为Memory Fence）指令，通过内存屏障指令来禁止特定类型的处理器重排序



**happens-before**

从JDK 5开始，Java使用新的**JSR-133内存模型**（除非特别说明，本文针对的都是JSR-133内存模型）。JSR-133使用happens- before的概念来阐述操作之间的内存可见性。

happens- before的概念：

+ 在JMM中，如果一个操作执行的结果需要对另一个操作可见，那么这两个操作之间必须要存在happens- before关系。这里提到的两个操作既可以是在一个线程之内，也可以是在不同线程之间。
+ **程序顺序规则**：一个线程中的每个操作，happens-before于该线程中的任意后续操作。
+ **监视器锁规则**：对一个锁的解锁，happens-before于随后对这个锁的加锁。
+ **volatile变量规则**：对一个volatile域的写，happens- before于任意后续对这个volatile域的读。
+ **传递性**：如果A happens-before B，且B happens-before C，那么Ahappens-before C。
+ 两个操作之间具有happens-before关系，**并不意味着前一个操作必须要在后一个操作之前执行**！happens-before仅仅要求前一个操作（执行的结果）对后一个操作可见，且前一个操作按顺序排在第二个操作之前（the first is visible to and ordered before the second）。



##### 3.2 重排序

重排序是指编译器和处理器为了**优化程序性能**而对指令序列进行重新排序的一种手段。

+ 如果两个操作访问同一个变量，且这两个操作中有一个为写操作，此时这两个操作之间就存在**数据依赖性**。（读后写，写后读，写后写）。有数据依赖关系的两个操作顺序不会被改变（**但是仅仅是单线程/单个处理器**）
+ **控制依赖**：if（）就是一种控制依赖，对此编译器和处理器会采用**猜测**执行来克服控制依赖对并行度的影响。
+ **as-if-serial语义**的意思是：不管怎么重排序（编译器和处理器为了提高并行度），（单线程）程序的执行结果不能被改变。编译器、runtime和处理器都必须遵守as-if-serial语义。
+ A happens before B，但是B的执行可以在A之前。因为A的结果不需要对B可见，而且重排序之后结果相同，所以JMM认为这里重排序并不非法
+ 重排序可能会破坏多线程的语义



##### 3.3 顺序一致性--内存模型

顺序一致性内存模型是一个理论参考模型，在设计的时候，处理器的内存模型和编程语言的内存模型都会以顺序一致性内存模型作为参照。

**数据竞争 & 顺序一致性**

数据竞争：

+ 在一个线程中写一个变量，另一个线程中读同一变量，而且写和读没有通过同步来排序，就会产生数据竞争
+ JMM对正确同步的多线程程序的内存一致性做了如下保证。**如果程序是正确同步的，程序的执行将具有顺序一致性（SequentiallyConsistent）**——即程序的执行结果与该程序在顺序一致性内存模型中的执行结果相同。
+ 具备顺序一致性的程序没有数据竞争？？



**顺序一致性内存模型**有两大特性：

+ 一个线程中的所有操作必须按照程序的顺序来执行。
+ （不管程序是否同步）所有线程都只能看到一个单一的操作执行顺序。在顺序一致性内存模型中，每个操作都必须原子执行且立刻对所有线程可见。
  + a1a2a3+b1b2b3  = a1a2a3b1b2b3 同步；也可能是 =a1b1a2b2a3b3 不同步，这样都符合顺序一致模型

1. 同步情况下，JMM和顺序一致性内存模型的差别：

   **JMM没有保证顺序一致性！！只在程序是正确同步的前提下，才具有顺序一致性！！并且在临界区内还是可能进行重排序优化，只不过结果和同步了的顺序一致性模型一样罢了**。JMM在具体实现上的基本方针为：在不改变（正确同步的）程序执行结果的前提下，尽可能地为编译器和处理器的优化打开方便之门。

2. 那么，未同步的情况下，程序是怎么执行的？？

   **最小安全性**：线程执行时读取到的值，要么是之前某个线程写入的值，要么是默认值（0，Null，False），JMM保证线程读操作读取到的值不会无中生有（Out Of Thin Air）的冒出来。

   未同步的程序，在两种模型下执行，结果都是不可预测的。

   + 单线程：顺序一致性内存模型是顺序执行的；JMM会重排
   + 多线程：顺序一致性模型保证所有线程看到的执行顺序是一样的，但是JMM不保证
   + 顺序一致模型保证所有读写操作都是原子性的；JMM的long和double不保证原子性

   

##### 3.4 volatile的内存语义

理解volatile特性的一个好方法是把对volatile变量的单个读/写，看成是使用同一个锁对这些单个读/写操作做了同步。锁的happens-before规则保证释放锁和获取锁的两个线程之间的内存可见性，这意味着对一个volatile变量的读，总是能看到（任意线程）对这个volatile变量最后的写入。

所以volatile具有可见性（读写操作的原子性），但是不保证原子性（其他操作可能不原子性）。

**volatile写操作的内存语义**：当写一个volatile变量时，JMM会把该线程对应的本地内存中的共享变量值刷新到主内存。

**volatile读的内存语义**：当读一个volatile变量时，JMM会把该线程对应的本地内存置为无效。线程接下来将从主内存中读取共享变量。

JMM是怎么实现volatile的内存语义的？

+ 分别限制编译器重排序和处理器重排序，插入内存屏障：第二个操作是volatile写、第一个操作是volatile读、volatile先写后读的两次操作，重排序被禁止了
+ 为了提供一种比锁更轻量级的线程之间通信的机制，JSR-133中才让volatile的内存语义和锁变的一样。



##### 3.5 锁的内存语义

锁的内存语义，其实同上volatile。

JMM具体怎么实现？

在ReentrantLock中，调用lock()方法获取锁；调用unlock()方法释放锁。

ReentrantLock的实现依赖于**Java同步器框架AbstractQueuedSynchronizer**（本文简称之为AQS）。AQS使用一个整型的volatile变量（命名为state）来维护同步状态，马上我们会看到，这个volatile变量是ReentrantLock内存语义实现的关键。

+ **公平锁**在释放锁的最后写volatile变量state，在获取锁时首先读这个volatile变量。

+ **非公平锁**以原子操作CAS的方式更新state变量，CAS同时具有volatile读写的内存语义
+ 因此锁的内存语义实现至少有两种方式：利用volatile、利用CAS



综上所述：java线程之间的通信现在有了4中方式：

+ 写volatile，读volatile
+ 写volatile，CAS更新
+ CAS更新，读volatile
+ CAS更新，CAS更新

concurrent包是基于这些特征实现的：

+ 首先，声明共享变量为volatile。
+ 然后，使用CAS的原子条件更新来实现线程之间的同步。
+ 同时，配合以volatile的读/写和CAS所具有的volatile读和写的内存语义来实现线程之间的通信。

<img src="/Users/chengleiyi/Library/Application Support/typora-user-images/image-20200619204145717.png" alt="image-20200619204145717" style="zoom:63%;" />



##### 3.6 final域的内存语义

对于final域，编译器和处理器要遵守两个重排序规则。

+ 在构造函数内对一个final域的写入，与随后把这个被构造对象的引用赋值给一个引用变量，这两个操作之间不能重排序。**在对象引用为任意线程可见之前，对象的final域已经被正确初始化过了**

+ 初次读一个包含final域的对象的引用，与随后初次读这个final域，这两个操作之间不能重排序。**如果该引用不为null，那么引用对象的final域一定已经被A线程初始化过了**

+ StoreStore屏障禁止把【final域的写】重排序到构造函数之外。**在构造函数返回之前，final域没有被初始化，如果对象引用在构造函数中逸出，被构造对象就对其他线程可见了，这时候可能会因为重排产生错误。**

  > 难懂！

+ 对于引用类型，写final域的重排序规则对编译器和处理器增加了如下约束：在构造函数内对一个final引用的对象的成员域的写入（例如obj.arr[0] = 2），与随后在构造函数外把这个被构造对象的引用赋值给一个引用变量，这两个操作之间不能重排序。



JSR-133保证：只要对象是正确构造的（被构造对象的引用在构造函数中没有“逸出”），那么不需要使用同步（指lock和volatile的使用）就可以保证任意线程都能看到这个final域在构造函数中被初始化之后的值。



##### 3.7 happens-before（3.2中讲过）

JMM把happens-before要求禁止的重排序分为了下面两类：

+ 会改变程序执行结果的重排序。JMM要求编译器和处理器必须禁止这种重排序。
+ 不会改变程序执行结果的重排序。JMM对编译器和处理器不做要求（JMM允许这种重排序）。



**happens-before的定义**

JSR-133使用happens-before的概念来指定两个操作之间的执行顺序。

+ 如果一个操作happens-before另一个操作，那么第一个操作的执行结果将对第二个操作可见，而且第一个操作的执行顺序排在第二个操作之前。**是JMM对程序员的承诺。**
+ 两个操作之间存在happens-before关系，并不意味着Java平台的具体实现必须要按照happens-before关系指定的顺序来执行。如果重排序之后的执行结果，与按happens-before关系来执行的结果一致，那么这种重排序并不非法（也就是说，JMM允许这种重排序）。**是JMM对编译器和处理器重排序的约束原则**
+ 因此，happens-before关系（正确同步的多线程）本质上和as-if-serial语义（单线程）是一回事。



##### 3.8 双重检查锁定与延迟初始化

双重检查锁定其实是一种错误的延迟初始化方法，因为在new一个对象的时候，分为三步：

1. 分配对象的内存空间；
2. 初始化对象；
3. 设置instance指向刚分配的内存地址；

其中2，3可能会被重排序，这样在另一个线程去访问该对象的时候，虽然不是null，但实际上并没有完成初始化。

解决方法（其实就是单例模式的几种正确的写法）：

+ volatile，禁止重排序；
+ 基于类初始化的解决方案
+ 如果确实需要对**实例字段**使用线程安全的延迟初始化，请使用上面介绍的基于volatile的延迟初始化的方案；如果确实需要对**静态字段**使用线程安全的延迟初始化，请使用上面介绍的基于类初始化的方案。



##### 3.9 小结

顺序一致性内存模型是一个理论参考模型，JMM和处理器内存模型在设计时通常会以顺序一致性内存模型为参照。在设计时，JMM和处理器内存模型会对顺序一致性模型做一些放松，因为如果完全按照顺序一致性模型来实现处理器和JMM，那么很多的处理器和编译器优化都要被禁止，这对执行性能将会有很大的影响。

越是追求性能的处理器，内存模型设计得会越弱。因为这些处理器希望内存模型对它们的束缚越少越好，这样它们就可以做尽可能多的优化来提高性能。

由于常见的处理器内存模型比JMM要弱，Java编译器在生成字节码时，会在执行指令序列的适当位置插入内存屏障来限制处理器的重排序。

**JMM是一个语言级的内存模型**

**处理器内存模型是硬件级的内存模型**

**顺序一致性内存模型是一个理论参考模型**

内存可见性保证

+ 单线程程序。单线程程序不会出现内存可见性问题。as-if-serial
+ 正确同步的多线程程序。正确同步的多线程程序的执行将具有顺序一致性（程序的执行结果与该程序在顺序一致性内存模型中的执行结果相同）。这是JMM关注的重点，JMM通过限制编译器和处理器的重排序来为程序员提供内存可见性保证。
+ 未同步/未正确同步的多线程程序。JMM为它们提供了最小安全性保障：线程执行时读取到的值，要么是之前某个线程写入的值，要么是默认值（0、null、false）。



#### 第四章 Java并发编程的基础

##### 4.1 线程简介

**什么是线程？**

现代操作系统调度的最小单元是线程，也叫轻量级进程，在一个进程里可以创建多个线程。

一个Java程序的运行不仅仅是main()方法的运行，而是main线程和多个其他线程的同时运行。

**使用多线程的优点：**

+ 能够利用更多的处理器核心
+ 更快的响应时间
+ 更好的编程模型

**线程的优先级？**

Java线程中通过一个成员变量Priority来控制优先级，优先级的范围从1～10，默认是5。

优先级高的获得时间片的数量多于低优先级的线程。

有些操作系统会忽略设定的优先级。

**线程的状态*6**

+ NEW：初始状态，被构建但是没有调用start；
+ RUNNABLE：运行状态，Java线程将操作系统中的就绪和运行两种状态统称”运行中：
+ BLOCKED：阻塞状态，线程阻塞于锁
+ WAITING：等待状态，需要等其他线程通知或中断
+ TIME_WAITING：超时等待状态，可以在指定的时间自行返回，执行sleep()方法正在计时
+ TERMINATED：终止状态，执行完毕

线程创建之后，调用start()方法开始运行。当线程执行wait()方法之后，线程进入等待状态。进入等待状态的线程需要依靠其他线程的通知才能够返回到运行状态，而超时等待状态相当于在等待状态的基础上增加了超时限制，也就是超时时间到达时将会返回到运行状态。当线程调用同步方法时，在没有获取到锁的情况下，线程将会进入到阻塞状态。线程在执行Runnable的run()方法之后将会进入到终止状态。

<u>但是阻塞在java. concurrent包中Lock接口的线程状态却是等待状态，因为java.concurrent包中Lock接口对于阻塞的实现均使用了LockSupport类中的相关方法。</u>

**Daemon线程**

Daemon线程是一种支持型线程，因为它主要被用做程序中后台调度以及支持性工作。

可以通过Thread.setDaemon(true) 将线程设置为Daemon线程，**需要在启动线程之前就设置好**

Daemon线程中的finally块不一定会执行，所以不能让它持有任何需要关闭的资源。



##### 4.2 启动和终止线程

调用start方法启动

**中断**

中断可以理解为线程的一个标志位属性，它表示一个运行中的线程是否被其他线程进行了中断操作。

线程通过isinterrupted() 来进行判断是否被中断，也可以用静态方法Thread.interrupted() 对当前线程的中断标志位进行复位。

如果该线程已经处于终结状态，即使该线程被中断过，在调用该线程对象的isinterrupted()的时候依旧会返回false。

这些方法在抛出InterruptedException之前，Java虚拟机会先将该线程的中断标识位清除，然后抛出InterruptedException，此时调用isInterrupted()方法将会返回false。



**过期的suspend()、resume()和stop()**

不建议使用这些方法的原因：

+ 以suspend()方法为例，在调用后，线程不会释放已经占有的资源（比如锁），而是占有着资源进入睡眠状态，这样容易引发死锁问题。
+ stop()方法在终结一个线程时不会保证线程的资源正常释放，通常是没有给予线程完成资源释放工作的机会，因此会导致程序可能工作在不确定状态下。

**这种通过标识位或者中断操作的方式能够使线程在终止时有机会去清理资源，而不是武断地将线程停止，因此这种终止线程的做法显得更加安全和优雅。**



##### 4.3 线程间通信

**volatile和synchronized关键字通信**

volatile修饰成员变量，synchronized修饰方法或者同步块，保证多个线程在同一时刻，只有一个线程处于方法或者同步块中，保证了线程对变量访问的可见性和排他性。

任意线程对Object（Object由synchronized保护）的访问，首先要获得Object的监视器。如果获取失败，线程进入同步队列，线程状态变为BLOCKED。当访问Object的前驱（获得了锁的线程）释放了锁，则该释放操作唤醒阻塞在同步队列中的线程，使其重新尝试对监视器的获取。



**wait() / notify() 等待、通知机制**

等待/通知机制，是指一个线程A调用了对象O的wait()方法进入等待状态，而另一个线程B调用了对象O的notify()或者notifyAll()方法，线程A收到通知后从对象O的wait()方法返回，进而执行后续操作。上述两个线程通过对象O来完成交互，而对象上的wait()和notify/notifyAll()的关系就如同开关信号一样，用来完成等待方和通知方之间的交互工作。

+ 使用wait()、notify()和notifyAll()时需要先对调用对象加锁。
+ 调用wait()方法后，线程状态由RUNNING变为WAITING，并将当前线程放置到对象的等待队列。
+ notify()或notifyAll()方法调用后，等待线程依旧不会从wait()返回，需要调用notify()或notifAll()的线程释放锁之后，等待线程才有机会从wait()返回。
+ notify()方法将等待队列中的一个等待线程从等待队列中移到同步队列中，而notifyAll()方法则是将等待队列中所有的线程全部移到同步队列，被移动的线程状态由WAITING变为BLOCKED。
+ 从wait()方法返回的前提是获得了调用对象的锁。

等待/通知的经典范式：等待方（消费者）和通知方（生产者）



**管道输入/输出流**

管道输入/输出流主要用于线程之间的数据传输，而传输的媒介为内存。

```java
PipedWriter out = new PipedWriter();
PipedReader in = new PipedReader();
out.connect(in); // 管道输入输出流需要进行连接，否则会抛出异常
```

+ 有名管道：可以用于同一系统中任意两个进程之间的通信；又被称为FIFO文件
+ 无名管道：只能用于父进程和子进程之间的通信



**Thread.join()的使用**

如果一个线程A执行了thread.join()语句，其含义是：当前线程A等待thread线程终止之后才从thread.join()返回。

线程Thread除了提供join()方法之外，还提供了join(longmillis)和join(long millis, int nanos)两个具备超时特性的方法。这两个超时方法表示，如果线程thread在给定的超时时间里没有终止，那么将会从该超时方法中返回。



**ThreadLocal的使用**

ThreadLocal，即线程变量，**是一个以ThreadLocal对象为键、任意对象为值的存储结构**。这个结构被附带在线程上，也就是说一个线程可以根据一个ThreadLocal对象查询到绑定在这个线程上的一个值。

对该类的操作实际上是对线程ThreadLocalMap的操作，内部是一个Entry数组，Entry继承自WeakReference,Entry内部的value用来存放通过ThreadLocal的set方法传递的值,key是ThreadLocal的弱引用。



##### 4.4 线程应用实例（有点难没看完）

**等待超时模式**

就是在等待通知范式基础上增加了超时控制。

**数据库连接池**

首先看一下连接池的定义。它通过构造函数初始化连接的最大上限，通过一个双向队列来维护连接，调用方需要先调用fetchConnection(long)方法来指定在多少毫秒内超时获取连接，当连接使用完成后，需要调用releaseConnection(Connection)方法将连接放回线程池





#### 第五章 Java中的锁

##### 5.1 Lock接口

Java SE 5之后，并发包中新增了**Lock接口（以及相关实现类）用来实现锁功能**，它提供了与synchronized关键字类似的同步功能，只是在使用时需要显式地获取和释放锁。

+ 虽然它缺少了（通过synchronized块或者方法所提供的）隐式获取释放锁的便捷性
+ 拥有了锁获取与释放的可操作性，lock()方法获取锁，unlock()方法释放锁；
+ 可中断的获取锁：lockInterruptibly() 方法，在锁的获取中可以中断当前线程；
+ 超时获取锁：tryLock(long time, timeunit unit)；
+ 可以尝试非阻塞的获取锁：tryLock()方法，没能获取锁，就返回false

**没有synchronized用起来方便，但是使用更灵活**

```java
Lock lock  = new ReentrantLock();
lock.lock(); // 不要将获取锁的过程写在try块中，因为如果在获取锁（自定义锁的实现）时发生了异常，异常抛出的同时，也会导致锁无故释放。
try{
  
} finally {
  lock.unlock();
}
```

**Lock接口的实现基本都是通过聚合了一个同步器的子类来完成线程访问控制的：同步器AbstractQueuedSynchronizer以及常用Lock接口的实现ReentrantLock**



##### 5.2 队列同步器（AQS）

AQS是用来构建锁或者其他同步组件的基础框架，**它使用了一个int成员变量表示同步状态，通过内置的FIFO队列来完成资源获取线程的排队工作**。

AQS主要是定义了若干同步状态获取和释放的方法来供自定义同步组件使用，管理同步状态。

**AQS的接口和示例**

同步器的设计是基于模板方法模式的，也就是说，**使用者需要继承同步器并重写指定的方法**，随后将同步器组合在自定义同步组件的实现中，并调用同步器提供的模板方法，而这些模板方法将会调用使用者重写的方法。

同步器提供的模板方法基本上分为3类：

+ 独占式获取与释放同步状态
+ 共享式获取与释放同步状态
+ 查询同步队列中的等待线程情况。

**AQS实现分析**

分析同步器是如何完成线程同步的？？

+ **同步队列**：同步器依赖内部的同步队列（一个FIFO双向队列）来完成同步状态的管理，当前线程获取同步状态失败时，同步器会将当前线程以及等待状态等信息构造成为一个节点（Node）并将其加入同步队列，同时会阻塞当前线程，当同步状态释放时，会把首节点中的线程唤醒，使其再次尝试获取同步状态。
+ **独占式同步状态获取与释放**：通过调用同步器的acquire(int arg)方法可以获取同步状态。该方法对中断不敏感，也就是由于线程获取同步状态失败后进入同步队列中，后续对线程进行中断操作时，线程不会从同步队列中移出
+ **共享式同步状态获取与释放**：通过调用同步器的acquireShared(int arg)方法可以共享式地获取同步状态。自旋过程中，如果当前节点的前驱为头节点时，尝试获取同步状态，如果返回值大于等于0，表示该次获取同步状态成功并从自旋过程中退出。
+ **独占式超时获取同步状态**：



##### 5.3 重入锁（ReentrantLock）

支持重进入的锁，它表示该锁能够支持一个线程对资源的重复加锁。除此之外，该锁的还支持获取锁时的公平和非公平性选择。

**什么是可重入？**

不可重入：当一个线程调用Mutex的lock()方法获取锁之后，如果再次调用lock()方法，则该线程将会被自己所阻塞

可重入：synchronized关键字隐式的支持重进入，比如一个synchronized修饰的递归方法，在方法执行时，执行线程在获取了锁之后仍能连续多次地获得该锁。

**在调用lock()方法时，已经获取到锁的线程，能够再次调用lock()方法获取锁而不被阻塞。**

**怎么实现可重入？**

通过判断当前线程是否为获取锁的线程来决定获取操作是否成功，如果是获取锁的线程再次请求，则将同步状态值进行增加并返回true，表示获取同步状态成功。

成功获取锁的线程再次获取锁，只是增加了同步状态值，这也就要求ReentrantLock在释放同步状态时减少同步状态值。同步状态减少到0的时候，将占有线程设置为null，并返回true，表示释放成功。



###### * 公平 / 非公平

+ ReentrantLock构造函数传入true --> 公平锁

+ 公平锁表示线程获取锁的顺序是按照线程加锁的顺序来分配的，即先到先得的顺序。FIFO
+ 非公平锁则是随机获得锁，有可能有些线程一直拿不到锁。
+ 非公平性锁可能使线程“饥饿”，但是由于开销更小，所以是默认模式。



##### 5.4 读写锁（ReentrantReadWriteLock）

一般的锁都是排他锁，即在同一个时刻只允许一个线程访问。

而读写锁在同一时刻可以允许多个读线程访问，但是在写线程访问时，所有的读线程和其他写线程均被阻塞。读写锁维护了一对锁，一个读锁和一个写锁，通过分离读锁和写锁，使得并发性相比一般的排他锁有了很大提升。

+ 支持非公平（默认）和公平的锁获取方式；
+ 该锁可重进入：获取读锁之后可以再次获取读锁；获取写锁之后可以再次获取写锁或者读锁；
+ 锁降级：写、读、写的次序中，写锁可以降级称为读锁；

**读写锁的实现分析**

+ **读写状态的设计**：依赖自定义同步器来实现同步功能，而读写状态就是其同步器的同步状态。读写锁将变量切分成了两个部分，高16位表示读，低16位表示写
+ **写锁的获取与释放**：如果当前线程已经获取了写锁，则增加写状态。如果当前线程在获取写锁时，读锁已经被获取（读状态不为0）或者该线程不是已经获取写锁的线程，则当前线程进入等待状态。
+ **读锁的获取与释放**：如果当前线程已经获取了读锁，则增加读状态。如果当前线程在获取读锁时，写锁已被其他线程获取，则进入等待状态。
+ **锁降级**是指把持住（当前拥有的）写锁，再获取到读锁，随后释放（先前拥有的）写锁的过程。不支持锁升级也是为了数据的可见性，如果任意线程进行了锁升级并修改了数据，那么其他获得读锁的线程数据不可见。



###### * 乐观 / 悲观锁

读写锁是一种悲观锁，在读的过程中不允许写，即不能锁升级。

stampLock是一种乐观锁，在读的过程中也可以写，通过比较、重读来检查是不是发生了修改，它的读锁不可重入。



##### 5.5 LockSupport工具

LockSupport定义了一组的公共静态方法，这些方法提供了**最基本的线程阻塞和唤醒功能**。以park开头的方法用来阻塞当前线程，以及unpark(Threadthread)方法来唤醒一个被阻塞的线程。



##### 5.6 Condition接口

任意一个Java对象，都拥有一组**监视器方法**（定义在java.lang.Object上），主要包括wait()、wait(long timeout)、notify()以及notifyAll()方法，这些方法与synchronized同步关键字配合，可以实现等待/通知模式。

**Condition接口也提供了类似Object的监视器方法（await / signal），与Lock配合（condition = reentrantLock.newCondition()）可以实现等待/通知模式**。



**Condition的实现分析**

ConditionObject是同步器AbstractQueuedSynchronizer的内部类。

+ 等待队列：
+ 等待：
+ 通知



#### 第六章 Java中的并发容器和框架









#### 第七章 Java中的13个原子操作类







#### 第八章 Java中的并发工具类

CountDownLatch、CyclicBarrier和Semaphore工具类提供了一种**并发流程控制的手段**，Exchanger工具类则提供了**在线程间交换数据的一种手段**。



##### 8.1 等待多线程完成 CountDownLatch

CountDownLatch**允许一个或多个线程等待其他线程完成操作**。

CountDownLatch的构造函数接收一个int类型的参数作为计数器，如果你想等待N个点完成，这里就传入N。

当调用CountDownLatch的countDown方法时，N就会减1；

CountDownLatch的await方法会阻塞当前线程，直到N变成零。

由于countDown方法可以用在任何地方，所以这里说的N个点，可以是N个线程，也可以是1个线程里的N个执行步骤。用在多个线程时，只需要把这个CountDownLatch的引用传递到线程里即可。

**实现的功能类似join() 方法**



##### 8.2 同步屏障CyclicBarrier

CyclicBarrier让一组线程到达一个屏障（也可以叫同步点）时被阻塞，直到最后一个线程到达屏障时，屏障才会开门，所有被屏障拦截的线程才会继续运行。

CyclicBarrier默认的构造方法是CyclicBarrier（int parties），其参数表示屏障拦截的线程数量，每个线程调用await方法告诉CyclicBarrier我已经到达了屏障，然后当前线程被阻塞。

CyclicBarrier还提供一个更高级的构造函数CyclicBarrier（int parties，Runnablebarrier-Action），用于在线程到达屏障时，优先执行barrierAction，方便处理更复杂的业务场景。

**应用场景：多线程计算数据，最后合并计算结果的场景**



**CyclicBarrier和CountDownLatch的区别**

CountDownLatch的计数器只能使用一次，而CyclicBarrier的计数器可以使用reset()方法重置。所以CyclicBarrier能处理更为复杂的业务场景。



##### 8.3 控制并发线程数 Semaphore

Semaphore（信号量）是用来**控制同时访问特定资源的线程数量**，它通过协调各个线程，以保证合理的使用公共资源。

**应用场景**

semaphore可以做流量控制，特别是共用资源有限的应用场景，比如数据库连接。

```java
private static ExecutorService threadpool = Executors.newFixedThreadPool(30);
private static Semophore s = new Semaphore(10);
threadpool.execute(new Runnable(){
  @Override
  public void run(){
    try{
      s.acquire();//线程使用Semaphore的acquire()方法获取一个许可证
      ////////do something////
      s.release();//使用完之后调用release()方法归还许可证
    } catch(InterruptedException e){
      
    }
  }
}
```



##### 8.4 线程间交换数据 Exchanger

Exchanger 是一个用于线程间协作的工具类。

它提供一个同步点，在这个同步点，两个线程可以交换彼此的数据。这两个线程通过exchange方法交换数据，如果第一个线程先执行exchange()方法，它会一直等待第二个线程也执行exchange方法，当两个线程都到达同步点时，这两个线程就可以交换数据，将本线程生产出来的数据传递给对方。

**遗传算法 / 校对工作**

如果两个线程有一个没有执行exchange()方法，则会一直等待，如果担心有特殊情况发生，避免一直等待，可以使用exchange（V x，longtimeout，TimeUnit unit）设置最大等待时长。



#### 第九章 Java中的线程池

Java中的线程池是运用场景最多的并发框架。

**Java中有ExecutorService、 RxJava、Disruptor 和 Akka 这些并发框架**



##### 9.1 线程池的实现原理

当提交一个新任务到线程池时，线程池**ThreadPoolExecutor**的处理流程如下。

+ 判断**核心线程池**里的线程是否都在执行任务（当前运行的线程少于corePoolSize）。如果不是，则创建一个新的工作线程来执行任务。如果核心线程池里的线程都在执行任务，则进入下个流程。
+ 判断**工作队列**是否已经满（将任务加入BlockingQueue）。如果工作队列没有满，则将新提交的任务存储在这个工作队列里。如果工作队列满了，则进入下个流程。**这样是为了避免频繁获取全局锁**
+ 判断**线程池**的线程是否都处于工作状态。如果没有，则创建一个新的工作线程来执行任务。
+ 如果已经满了（创建新线程将使当前运行的线程超出maximumPoolSize），则交给饱和策略来处理这个任务，RejectedExecutionHandler.rejectedExecution()方法。



##### 9.2 线程池的使用

**创建线程池**

```java
new ThreadPoolExecutor(corePoolSize, maximumPoolSize, keepAliveTime, milliseconds, runnableTaskQueue, handler);
```

+ corePoolSize（线程池的基本大小）
+ runnableTaskQueue（任务队列）
  + ArrayBlockingQueue
  +  LinkedBlockingQueue
  + SynchronousQueue
  + PriorityBlockingQueue
+ maximumPoolSize（线程池最大数量）
+ RejectedExecutionHandler（饱和策略）
  + AbortPolicy：直接抛出异常。
  + CallerRunsPolicy：只用调用者所在线程来运行任务。
  + DiscardOldestPolicy：丢弃队列里最近的一个任务，并执行当前任务。
  + DiscardPolicy：不处理，丢弃掉。



**向线程池提交任务**

+ execute()：提交不需要返回值的任务
+ submit()：提交需要返回值的任务，线程池会返回一个future类型的对象，通过这个future对象可以判断任务是否执行成功，并且可以通过future的get()方法来获取返回值，get()方法会阻塞当前线程直到任务完成



**关闭线程池**

调用线程池的shutdown或shutdownNow方法来关闭线程池

原理是遍历线程池中的工作线程，然后逐个调用线程的interrupt方法来中断线程，所以无法响应中断的任务可能永远无法终止



**合理配置线程池**

+ 任务的性质：CPU密集型任务、IO密集型任务和混合型任务。CPU密集型任务应配置尽可能小的线程，如配置Ncpu+1个线程的线程池。由于IO密集型任务线程并不是一直在执行任务，则应配置尽可能多的线程，如2*Ncpu。
+ 任务的优先级：高、中和低。优先级不同的任务可以使用优先级队列PriorityBlockingQueue来处理。
+ 任务的执行时间：长、中和短。可以交给不同规模的线程池来处理，或者可以使用优先级队列
+ 任务的依赖性：是否依赖其他系统资源，如数据库连接。



#### 第十章 Executor框架

Java的线程既是工作单元，也是执行机制。从JDK 5开始，把工作单元与执行机制分离开来。工作单元包括Runnable和Callable，而**执行机制由Executor框架提供**。

##### 10.1 Executor框架简介

**两级调度模型**

在上层，Java多线程程序通常把应用分解为若干个任务，然后使用用户级的调度器（Executor框架）将这些任务映射为固定数量的线程；在底层，操作系统内核将这些线程映射到硬件处理器上。

**Executor的结构**

+ 任务。包括被执行任务需要实现的接口：Runnable接口或Callable接口

+ 任务的执行。包括任务执行机制的核心接口Executor，以及继承自Executor的ExecutorService接口。Executor框架有两个关键类实现了ExecutorService接口（ThreadPoolExecutor和ScheduledThreadPoolExecutor）。

  Executor==>ExecutorService==>ThreadPoolExecutor

  ​													==>ScheduledThreadPoolExecutor

+ 异步计算的结果。包括接口Future和实现Future接口的FutureTask类。



**使用过程**

主线程首先要**创建实现**Runnable或者Callable接口的任务对象。

工具类Executors可以把一个Runnable对象封装为一个Callable对象（Executors.callable（Runnable task）或Executors.callable（Runnable task，Object resule））。然后可以把Runnable对象直接交给ExecutorService执行（ExecutorService.**execute**（Runnable command））；

或者也可以把Runnable对象或Callable对象提交给ExecutorService执行（Executor-Service.**submit**（Runnabletask）或ExecutorService.submit（Callable<T>task））。

如果执行ExecutorService.submit（…），ExecutorService将返回一个实现Future接口的对象（到目前为止的JDK中，返回的是FutureTask对象）。由于FutureTask实现了Runnable，程序员也可以创建FutureTask，然后直接交给ExecutorService执行。

最后，主线程可以执行FutureTask.get()方法来等待任务执行完成。主线程也可以执行FutureTask.cancel（boolean mayInterruptIfRunning）来取消此任务的执行。

​												

**Executor的成员组件**

+ ThreadPoolExecutor：通常使用工厂类Executors来创建；
  + FixedThreadPool ：使用固定线程数。适用于为了满足资源管理的需求，而需要限制当前线程数量的应用场景，它适用于负载比较重的服务器。
  + SingleThreadExecutor：使用单个线程。适用于需要保证顺序地执行各个任务；并且在任意时间点，不会有多个线程是活动的应用场景。
  + CachedThreadPool：会根据需要创建新线程。大小无界的线程池，适用于执行很多的短期异步任务的小程序，或者是负载较轻的服务器。
+ ScheduledThreadPoolExecutor：
  + ScheduledThreadPoolExecutor：包含若干个线程。适用于需要多个后台线程执行周期任务，同时为了满足资源管理的需求而需要限制后台线程的数量的应用场景。
  + SingleThreadScheduledExecutor：只包含一个线程。适用于需要单个后台线程执行周期任务，同时需要保证顺序地执行各个任务的应用场景。
+ Future接口：Future接口和实现Future接口的FutureTask类用来表示异步计算的结果。



















#### 第十一章 Java并发编程实践







